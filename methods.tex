\section{Unit testing methods}
\subsection{Testing for expected result}
The intuitive way is to write a test that tests the output of each function.

If we have a \texttt{fooBar.cpp} with the following definition:

\cpp{fooBar.cpp}

To ensure \texttt{fooBar()} always return \texttt{"qux"}, we can write a test to test this behaviour:

\cpp{fooBar.test.cpp}

The \texttt{ASSERT\_EQUAL} macro function would compare the result of \texttt{fooBar()} with \texttt{"qux"} and trigger an error if they are not equal.
This macro function can be implemented very easily:

\cpp{assert.h}

In this implementation, if the values are not equal, an exception string is thrown.

Different unit testing frameworks may have different error behaviour, and some are able to integrate with IDEs for advanced analysis.

Some other common assertions include:
\begin{itemize}
	\item Null checks
	\item Arithmetic comparisons $<$ $\leq$ $>$ $\geq$
	\item That an expected exception must be thrown
\end{itemize}

By running a series of similar tests every time before moving to another project subcomponent,
bugs can be identified before it spreads to other components.
This is particularly helpful when certain bugfixes might result in prototype changes,
resulting in incompatibility with other components during bugfixes.

\subsection{Increasing the test size}
If a function accepts parameters, multiple calls with different values should be passed to the function.

Suppose we want to test a function that converts a number to scientific notation rounded to 3 significant figures:

\cpp{sciNot1.cpp}

Testing the simple case of rounding $1235$ to $124\times10^1$ is successful:

\cpp{sciNot1.test.cpp}
\cod{sciNot1.log}

However, adding more test parameters, such as negative inputs, would turn out that the function does not always function as expected:

\cpp{sciNot2.test.cpp}
\cod{sciNot2.log}

From this, we can identify that a negative input results in a negative value, apparently because of the \texttt{log10} function call.
So a simple workaround of fixing the input to a positive number can be made:

\cpp{sciNot3.cpp}
\cod{sciNot3.log}

\subsection{Generating test cases randomly}
Since a larger test size is more likely to catch bugs, it is a good idea to generate a large sample of test cases.

Generating random test cases also avoids the case where a developer is writing specific test cases (e.g. only multiples of 7)
to avoid unit tests from reflecting a known bug in the code.

\subsubsection{Random output, inverse-evaluated input}
But a contradictory condition arises: If the test cases are generated, how to test if the result is correct?
It is not possible to calculate the value in the test generator, because that would involve reimplementing the tested function.

Instead, if an inverse of the tested function can be written
(or to generate any of the possible inverse values if the function is not an injection),
the random generator can be used to generate random results instead.

Nevertheless, the inverse function is often harder to write and likely to have bugs than the function to test for,
and is usually unintuitive to be used as a way of software specification.
A better approach is to use property-based testing.

\subsubsection{Property-based testing}
Instead of comparing if the output is equal to an expected result,
property-based testing compares the characteristics of the output to determine if it is reasonable.

In C++, the \href{https://github.com/emil-e/rapidcheck}{rapidcheck} library
provides a property-based testing framework that generates a random sequence of data by type for assertion.

For example, in the 3-sigifnicant-figure example above, the requirements are:

\begin{enumerate}
	\item Given an input $n$, the output $\hat{n} = d \times 10^{x}$ is returned.
	\item The result significand $d$ must have exactly 3 significant figures, i.e. $d \in [100, 999]$
	\item The error must be correct to the \nth{3} significant figure: $\hat{n} - n \in [-0.5 \times 10^{x}, 0.5 \times 10^{x})$
\end{enumerate}

The \nth{1} requirement is defined through the function prototype,
and the \nth{2} and \nth{3} requirements can be specified by the following test:

\cpp{sciNot5.test.cpp}
\cod{sciNot5.log}

The data generated by rapidcheck (or any other property-based testing framework) shoild be further filtered
in the test to eliminate incorrect values, or a custom input generator can be written to
generate inputs appropriate for the tested unit.
The rapidcheck framework provides a \texttt{Gen} API to customize input data generation.

\subsubsection{Reimplement algorithm by brute-force}
Even though the test only expresses the software specification, it may still be difficult to implement.
Suppose the following function is specified:

\begin{itemize}
	\item Parameter \texttt{int n}: the number of nodes
	\item Parameter \texttt{vector<pair<int, int>> edges}: each pair is two numbers indicating two node IDs of a directed edge.
	\item Node IDs are integers in the range $[0, n)$.
	\item If a Hamiltonian circuit is present, return any possible \texttt{vector<int> *} such that
		the node IDs in the vector represent a Hamiltonian circuit for the graph.
	\item If a Hamiltonian circuit is not present, return \texttt{NULL}.
\end{itemize}

Assume the function is implemented in a certain polynomial-time algorithm
(which is possible given more specifications on the graph,
but it is omitted as Hamiltonian circuit algorithm is not the focus of this project).

While it is simple to test for the correctness for returned vectors, it is very difficult to test if returning \texttt{NULL} is correct.
The specification "Hamiltonian circuit is not present" is very well-defined, but it is still not possible to validate.
In this case, a brute-force approach can be used to test for the correctness.

Although the function was implemented in an efficient polynomial-time algorithm, tests do not strictly require a high performance.
It is therefore appropriate to test the new algorithm
with a potentially less error-prone and more reliable algorithm using brute-force, i.e. NP time.
This is because unit tests do not have to be capable of tackling with large data sets;
light-weightedness is one of the core concepts of unit testing.
(Stress testing is another topic not related to unit testing)

\subsubsection{Testing for edge cases}
Some common special cases should be included in the test data set explicitly, since they are common sources of error:

\begin{itemize}
	\item Empty strings, multi-line strings, strings with Unicode, strings woth emoji
	\item Small numbers: $0, 1, 2, -1, -2, 0.5, -0.5$
	\item Large numbers: $2^{31}-1$, $2^{32}-1$, $2^{63}-1$, $2^{64}-1$
	\item Special floats: \texttt{1/0} ($+\infty$), \texttt{-1/0} ($-\infty$), \texttt{0/0} (\texttt{NaN})
\end{itemize}
\rem{E.g. test for empty strings, Float.INFINITY, 0, etc.}
