\section{Unit testing methods}
\subsection{Testing for expected result}
The intuitive way is to write a test that tests the output of each function.

\cpp{fooBar.test.cpp}

The \texttt{ASSERT\_EQUAL} macro function would compare the result of \texttt{fooBar()} with \texttt{"qux"} and trigger an error if they are not equal.
This macro function can be implemented very easily:

\cpprng{assert.h}{2}{4}

Some other common assertions include:
\begin{itemize}
	\item Null checks
	\item Arithmetic comparisons > >= < <=
	\item That an exception must be gracefully thrown
\end{itemize}

By running a series of similar tests every time before moving to another project subcomponent,
bugs can be identified before it spreads to other components.
This is particularly helpful when certain bugfixes might result in prototype changes,
resulting in incompatibility with other components during bugfixes.

\subsection{Increasing the test size}
If a function accepts parameters, multiple calls with different values should be passed to the function.

Suppose we want to test a function that converts a number to scientific notation rounded to $$3$$ significant figures:

\cpp{sciNot.cpp}

\subsection{Generating test parameters}
If a function accepts a parameter, it is not possible to execute a test on every possible parameter value.
Instead, the parameters can be generated randomly in every test.
By supplying a test sample large enough, most bugs can be discovered by the unit test.

Suppose we want to test a function that rounds a number to 3 significant figures:

\rem{Generate parameters randomly, possibly by reverse calculation}

\subsubsection{Testing for edge cases}
\rem{E.g. test for empty strings, Float.INFINITY, 0, etc.}
